## ⚙️ Code Breakdown: How the API Works

This section provides a detailed look at the different parts of the codebase and their responsibilities.

### 1. Import Dependencies

- Imports essential libraries: `fastapi`, `pydantic`, `uvicorn`, `dotenv`, `google.generativeai`, and standard Python modules (`os`, `json`, `re`).
- Sets up the necessary tools for building the web API, handling data models, running the server, managing environment variables, interacting with the LLM, and basic utilities for string processing and JSON handling.

### 2. Load Environment Variables

- Uses `load_dotenv()` to load variables from the `.env` file located in the project root.
- Retrieves the `GOOGLE_API_KEY` environment variable, which is crucial for authenticating with the Gemini API.
- Crucially, it includes a check: if the `GOOGLE_API_KEY` is not found, it raises a `ValueError` with a clear message guiding the user to set it up in the `.env` file or environment.

### 3. Initialize Google Gemini API

- Configures the `google.generativeai` library using `genai.configure(api_key=GOOGLE_API_KEY)` with the key loaded from the environment.
- Creates a global instance named `gemini_model` using `genai.GenerativeModel("gemini-1.5-pro-latest")`. This model instance is reused for all classification requests.
- Includes error handling during initialization: if configuration or model loading fails (e.g., due to an invalid API key, network issues, etc.), it logs the error and raises a `RuntimeError`, preventing the application from starting in an unusable state.

### 4. Define Email Classification Tags

- A list `EMAIL_TAGS` is defined, containing the allowed classification categories. Examples include: "Bug Report", "Feature Request", "Refund Request", "Technical Support", "Sales Inquiry", "Marketing Email", "Other", and "Spam/Irrelevant".
- These tags serve as the controlled vocabulary for the LLM's output, ensuring consistent and predictable classification results.

### 5. Define Prompt Generation Function (`get_prompt_batch`)

- This function takes a list of email strings as input.
- It formats the `EMAIL_TAGS` list into a human-readable bulleted string for inclusion in the prompt, clearly showing the model the valid options.
- It structures the input emails within the prompt, typically prefixing each with something like "Email 1:", "Email 2:", etc., to help the model process them distinctly.
- Constructs a detailed prompt instruction for the Gemini model. The prompt explicitly asks the model to:
  - Analyze each email _individually_.
  - Assign _one or more_ tags _strictly from the provided list_.
  - Use "Other" for emails that don't fit specific categories and "Spam/Irrelevant" for irrelevant or unsolicited content.
  - Return the response in a specific JSON format: an array of objects, `[{"tags": [...]}, {"tags": [...]}, ...]`, ensuring the order of the objects in the array matches the order of the input emails.

### 6. Define LLM Interaction Function (`classify_emails_with_gemini`)

- Handles the asynchronous communication with the Google Gemini API.
- First, it checks if the global `gemini_model` instance was successfully initialized, raising a `RuntimeError` if not.
- Sends the prompt generated by `get_prompt_batch` to the model using `gemini_model.generate_content(prompt)`.
- Includes checks for cases where the API returns an empty response or a response without text content, logging a warning and raising a `RuntimeError`.
- **Response Cleaning:** Uses regular expressions (`re.sub`) to remove common markdown code block wrappers (like `json\n or \n`) that LLMs sometimes include in their JSON outputs, ensuring the string is pure JSON.
- **JSON Parsing:** Attempts to parse the cleaned response string into a Python list/dictionary structure using `json.loads()`.
- Validates that the result of the JSON parsing is indeed a list, raising a `ValueError` otherwise.
- Implements robust error handling:
  - Catches `json.JSONDecodeError` specifically if the cleaned response text is not valid JSON, logging the problematic text to aid debugging.
  - Catches other potential exceptions from the API interaction (e.g., API quota errors, network issues) and raises them as `RuntimeError` after logging.
- Returns the parsed Python list, which represents the classification results for the batch of emails.

### 7. Define Data Models (Pydantic)

- **`EmailListRequest`:** Defines the expected structure of the incoming JSON request body for the `/classify` endpoint. It requires a field named `emails` which must be a Python `list` containing `str` objects. Pydantic automatically validates incoming requests against this model.
- **`TaggedEmailResult`:** Defines the structure for a single email's classification result within the response. It has a `tags` field, which is strictly defined as a `List[str]`.
- **`EmailClassificationResponse`:** Uses `RootModel[List[TaggedEmailResult]]` to specify that the _entire_ response body from the `/classify` endpoint should be a JSON array (`List`) where _each item_ in the array must conform to the `TaggedEmailResult` model. This ensures structured and validated API responses.

### 8. Set Up FastAPI Application

- An instance of the `FastAPI` application (`app`) is created. Metadata like `title`, `description`, and `version` are included for the automatically generated API documentation (Swagger UI).
- Two main API endpoints are defined using FastAPI decorators:
  - `GET /`: A simple health check endpoint that returns a success message.
  - `POST /classify`: The primary endpoint for submitting emails for classification. The `response_model=EmailClassificationResponse` argument ensures the output is validated against the Pydantic model and documented correctly.

### 9. Process `/classify` Endpoint Request (`classify_emails_endpoint`)

- This asynchronous function serves as the request handler for `POST` requests to `/classify`.
- FastAPI automatically validates the incoming JSON request body against the `EmailListRequest` Pydantic model and provides the validated data as the `request: EmailListRequest` argument.
- It includes a check: if the input `emails` list is empty, it immediately returns an empty list `[]`, avoiding unnecessary calls to the LLM.
- Calls the `get_prompt_batch()` function, passing the list of email strings from the request body, to generate the appropriate prompt for Gemini.
- Calls the `classify_emails_with_gemini()` function, passing the generated prompt, to send it to the Gemini API and receive the raw classification results.
- Returns the results obtained from `classify_emails_with_gemini()`. FastAPI automatically serializes this Python list of dictionaries into a JSON array based on the `EmailClassificationResponse` `response_model` definition.
- Implements comprehensive error handling for this endpoint:
  - Catches specific exceptions (`ValueError`, `RuntimeError`, `json.JSONDecodeError`) that might be raised by the internal logic functions (`get_prompt_batch`, `classify_emails_with_gemini`). These caught errors are logged and then raised as `HTTPException` with a `status_code=500` (Internal Server Error) to provide a consistent API error response format.
  - Includes a broader `Exception` catch-all for any unexpected errors, also raising them as HTTP 500 errors.

### 10. Run the Server

- The standard `if __name__ == "__main__":` block is used to ensure the Uvicorn server startup code only runs when the script is executed directly.
- It calls `uvicorn.run()` to start the development web server.
- Configured to run the `app` instance (the FastAPI application) from the current file (`main`) on `host="0.0.0.0"` (listening on all network interfaces) and `port=8000`.
- `reload=True` is typically included for development, enabling the server to automatically restart when code changes are detected.
- A note is usually included advising the user to use the `uvicorn main:app --host 0.0.0.0 --port 8000 --reload` command directly when running from the terminal for better handling of the `--reload` flag compared to running just `python main.py`.
